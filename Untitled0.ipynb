{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "wAI1Yl21hOxI"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random \n",
        "import math\n",
        "import re \n",
        "from os.path import exists "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model = nn.Transformer(nhead = 16, num_encoder_layers = 12)\n",
        "src = torch.rand((10, 32, 512))\n",
        "tgt = torch.rand((20, 32, 512))\n",
        "out = transformer_model(src, tgt)\n",
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKm9-DPfiRJ4",
        "outputId": "cb551d51-5e09-4976-e0ba-eca0080e9f8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.9592e-01,  4.2110e-01,  1.9799e+00,  ..., -1.8232e+00,\n",
              "           8.9337e-03,  5.0581e-01],\n",
              "         [-1.4271e+00, -7.4483e-01,  1.2145e+00,  ..., -1.2719e+00,\n",
              "          -4.2365e-01, -8.2322e-01],\n",
              "         [-5.1358e-01, -3.4527e-01,  1.9460e+00,  ..., -1.4801e+00,\n",
              "          -1.3802e+00, -4.3133e-01],\n",
              "         ...,\n",
              "         [-1.0320e-01,  5.5729e-01,  2.1463e+00,  ..., -2.4291e+00,\n",
              "          -1.7457e+00, -5.3495e-01],\n",
              "         [-1.6167e-01, -5.1827e-01,  8.2001e-01,  ..., -1.7656e+00,\n",
              "          -1.4371e-03, -2.2060e-01],\n",
              "         [-1.3595e-01, -1.2292e+00,  1.7365e+00,  ..., -1.5104e+00,\n",
              "          -9.7557e-01, -6.8369e-01]],\n",
              "\n",
              "        [[-7.8360e-01,  7.4953e-04,  1.9794e+00,  ..., -2.2217e+00,\n",
              "          -2.8295e-01, -5.9601e-01],\n",
              "         [-1.5299e+00, -1.1840e-02,  1.4529e+00,  ..., -1.3943e+00,\n",
              "          -4.5483e-01, -1.3080e+00],\n",
              "         [-8.1109e-01, -3.3052e-01,  8.9603e-01,  ..., -1.4662e+00,\n",
              "          -7.5224e-01, -8.3836e-01],\n",
              "         ...,\n",
              "         [-4.9217e-01, -2.8871e-01,  1.4110e+00,  ..., -1.6571e+00,\n",
              "          -1.3203e+00, -1.4221e+00],\n",
              "         [ 3.3441e-01, -2.5469e-01,  7.1235e-01,  ..., -2.5260e+00,\n",
              "          -2.8392e-01, -8.0777e-01],\n",
              "         [-1.1183e+00, -1.2991e+00,  5.7199e-01,  ..., -1.6926e+00,\n",
              "          -7.9477e-01,  3.2479e-01]],\n",
              "\n",
              "        [[-1.2894e+00, -7.2649e-01,  1.2482e+00,  ..., -2.5545e+00,\n",
              "          -3.3418e-01, -6.8624e-01],\n",
              "         [-1.6160e+00,  9.8933e-02,  8.1355e-01,  ..., -1.3514e+00,\n",
              "          -1.5796e+00, -1.4486e-01],\n",
              "         [-2.5675e-01, -1.4340e+00,  1.8878e+00,  ..., -1.8895e+00,\n",
              "          -1.4976e+00, -1.1582e-01],\n",
              "         ...,\n",
              "         [-5.2864e-01,  6.3556e-01,  1.7942e+00,  ..., -8.8487e-01,\n",
              "          -1.0984e+00, -6.2095e-01],\n",
              "         [-3.9022e-02, -7.0302e-01,  1.5627e+00,  ..., -2.5835e+00,\n",
              "           2.9574e-02, -6.5364e-01],\n",
              "         [-9.3464e-01, -6.9593e-01,  2.1701e+00,  ..., -1.5332e+00,\n",
              "          -1.0189e+00, -4.6873e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-2.3893e-01, -8.0589e-01,  1.1530e+00,  ..., -1.5353e+00,\n",
              "          -7.9372e-01, -8.6527e-02],\n",
              "         [-7.3660e-01, -1.4387e-01,  9.6637e-01,  ..., -1.4560e+00,\n",
              "          -7.3746e-01, -5.6676e-01],\n",
              "         [-1.0917e+00, -2.0394e-01,  2.6394e+00,  ..., -1.1166e+00,\n",
              "          -1.9480e+00, -8.3397e-01],\n",
              "         ...,\n",
              "         [-6.0746e-02, -2.6440e-01,  9.3625e-01,  ..., -1.1614e+00,\n",
              "          -5.4021e-01, -8.7950e-01],\n",
              "         [-2.9407e-01, -1.9302e-01,  2.1724e+00,  ..., -1.7133e+00,\n",
              "          -7.6327e-01, -5.3838e-01],\n",
              "         [-6.4541e-01, -1.0977e+00,  1.7937e+00,  ..., -1.4049e+00,\n",
              "          -9.4092e-01, -2.4760e-01]],\n",
              "\n",
              "        [[-8.5602e-01, -4.1628e-01,  9.8117e-01,  ..., -1.8132e+00,\n",
              "          -8.5510e-01, -7.9425e-01],\n",
              "         [-8.8459e-01, -1.5509e-01,  1.6129e+00,  ..., -1.4379e+00,\n",
              "          -8.6570e-01, -6.4583e-01],\n",
              "         [-5.0043e-01, -1.3964e+00,  1.4527e+00,  ..., -1.5090e+00,\n",
              "          -1.7829e+00, -4.0479e-01],\n",
              "         ...,\n",
              "         [-4.5151e-01,  4.4784e-01,  2.1129e+00,  ..., -7.4466e-01,\n",
              "          -1.0031e+00, -1.1435e+00],\n",
              "         [-6.9938e-01, -8.5560e-01,  1.2452e+00,  ..., -2.0691e+00,\n",
              "           1.1365e-01, -3.8610e-01],\n",
              "         [-1.1654e+00, -1.4808e+00,  1.7611e+00,  ..., -1.8103e+00,\n",
              "          -1.0430e+00, -8.5379e-01]],\n",
              "\n",
              "        [[-9.6352e-02, -7.7253e-01,  1.4255e+00,  ..., -1.4600e+00,\n",
              "          -5.8508e-01, -3.7147e-01],\n",
              "         [-9.9945e-01,  1.1719e-02,  1.2300e+00,  ..., -8.5500e-01,\n",
              "          -1.1845e+00, -3.2398e-01],\n",
              "         [-6.6536e-01, -2.2903e-01,  3.0330e+00,  ..., -2.2160e+00,\n",
              "          -1.4790e+00, -4.3149e-01],\n",
              "         ...,\n",
              "         [-1.8382e-01, -8.1312e-02,  1.5137e+00,  ..., -2.1600e+00,\n",
              "          -1.0718e+00,  3.0557e-01],\n",
              "         [-5.5991e-01, -1.4008e-01,  4.4180e-01,  ..., -2.3094e+00,\n",
              "          -8.5415e-01,  1.5460e-01],\n",
              "         [-1.1860e+00, -1.2645e+00,  1.7093e+00,  ..., -1.3311e+00,\n",
              "          -8.8248e-01,  2.8028e-02]]], grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6WkKgRZjPxp",
        "outputId": "080ba0cd-317c-40e6-e802-08e1af8883cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 32, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "1uWYLc37jVJq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXpWfc2Knn8Q",
        "outputId": "beaef3c5-3fa3-4e8f-d627-caa886d7d051"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unicodedata2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ893bYCw1Ka",
        "outputId": "82e7326d-f582-4d5e-da52-cda3b1ee5c84"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unicodedata2\n",
            "  Downloading unicodedata2-14.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (467 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20 kB 37.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 30 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 51 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 71 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 81 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 102 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 112 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 122 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 133 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 143 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 153 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 163 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 174 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 184 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 194 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 204 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 215 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 225 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 235 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 245 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 256 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 266 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 276 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 286 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 296 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 307 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 317 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 327 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 337 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 348 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 358 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 368 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 378 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 389 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 399 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 409 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 419 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 430 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 440 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 450 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 460 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 467 kB 7.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: unicodedata2\n",
            "Successfully installed unicodedata2-14.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata"
      ],
      "metadata": {
        "id": "fcYSbYNew8qC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS-IQByhnpQA",
        "outputId": "247a6847-a027-46af-8d7b-83913f97af96"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-17 01:27:14--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 18.65.229.105, 18.65.229.14, 18.65.229.70, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|18.65.229.105|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip            100%[===================>]   2.75M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-05-17 01:27:14 (50.6 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE7DcvMBoFi-",
        "outputId": "660d10b7-33f4-41e0-bc5f-af6b34ab246f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "4KBtZNp5pLp6"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "metadata": {
        "id": "C8x66jTFsqgF"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "metadata": {
        "id": "Fz_5UCJcs0yG"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "metadata": {
        "id": "W-ME4QrQumqE"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNfyCTahvGVb",
        "outputId": "ee9449e8-a68c-45bf-e44c-8e75d93a38a6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4345\n",
            "eng 2803\n",
            "['vous etes merveilleux .', 'you re wonderful .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from itertools import islice"
      ],
      "metadata": {
        "id": "jz7HQG1t1YxD"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(islice(input_lang.word2index.items(), 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NetXJj61PDL",
        "outputId": "7ab14ead-b026-44f9-985e-4c7cb9ceacc5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('j', 2),\n",
              " ('ai', 3),\n",
              " ('ans', 4),\n",
              " ('.', 5),\n",
              " ('je', 6),\n",
              " ('vais', 7),\n",
              " ('bien', 8),\n",
              " ('ca', 9),\n",
              " ('va', 10),\n",
              " ('suis', 11)]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(islice(output_lang.word2index.items(), 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvdCt6F01vsu",
        "outputId": "f8547a00-dbb9-49d9-a414-563c933ea576"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 2),\n",
              " ('m', 3),\n",
              " ('.', 4),\n",
              " ('ok', 5),\n",
              " ('fat', 6),\n",
              " ('fit', 7),\n",
              " ('hit', 8),\n",
              " ('!', 9),\n",
              " ('ill', 10),\n",
              " ('sad', 11)]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(islice(output_lang.word2count.items(), 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p94iNeMe1vkd",
        "outputId": "03f38d97-e592-4048-d213-2f2d79670f98"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 4305),\n",
              " ('m', 3480),\n",
              " ('.', 10373),\n",
              " ('ok', 10),\n",
              " ('fat', 19),\n",
              " ('fit', 10),\n",
              " ('hit', 4),\n",
              " ('!', 82),\n",
              " ('ill', 7),\n",
              " ('sad', 14)]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Encoder"
      ],
      "metadata": {
        "id": "VYHPgkdb3DBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\n",
        "    output = embedded\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "t75ebre3yzf7"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Decoder"
      ],
      "metadata": {
        "id": "-Dxn_Pm53mzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size):\n",
        "    super(DecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "    self.out = nn.Linear(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    output = self.embedding(input).view(1, 1, -1)\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "    output = self.softmax(self.out(output[0]))\n",
        "    return output, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "WxY8zqNw3Rft"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "  def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "    super(AttnDecoderRNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.dropout_p = dropout_p\n",
        "    self.max_length = max_length\n",
        "\n",
        "    self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "    self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "    self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "    self.dropout = nn.Dropout(self.dropout_p)\n",
        "    self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "    self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "  def forward(self, input, hidden, encoder_outputs):\n",
        "    embedded = self.embedding(input).view(1, 1, -1)\n",
        "    embedded = self.dropout(embedded)\n",
        "\n",
        "    attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "    attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "    output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "    output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "    output = F.relu(output)\n",
        "    output, hidden = self.gru(output, hidden)\n",
        "\n",
        "    output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "    return output, hidden, attn_weights\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "0P4nL2fL32Od"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "TKFtNpz9487F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_lang.word2index"
      ],
      "metadata": {
        "id": "SKSBtcyp6X5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "  return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "  indexes = indexesFromSentence(lang, sentence)\n",
        "  indexes.append(EOS_token)\n",
        "  return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "  input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "  target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "  return (input_tensor, target_tensor)"
      ],
      "metadata": {
        "id": "x-H5AhHJ4U1i"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "metadata": {
        "id": "x_m08rCS5Iwe"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "VMm9n66A7QN7"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "lyrH3RS6By7s"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "GN8KWc5Z7SjU"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img alt=\"\" src=\"../_images/attention-decoder-network.png\">"
      ],
      "metadata": {
        "id": "w57KsS-jFCgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s14QweSp7XFp",
        "outputId": "709f6fa0-dcec-4d80-bc4a-609d04a01583"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m 16s (- 17m 47s) (5000 6%) 2.8409\n",
            "2m 28s (- 16m 2s) (10000 13%) 2.2688\n",
            "3m 40s (- 14m 41s) (15000 20%) 1.9576\n",
            "4m 53s (- 13m 27s) (20000 26%) 1.7263\n",
            "6m 5s (- 12m 11s) (25000 33%) 1.5655\n",
            "7m 18s (- 10m 57s) (30000 40%) 1.3505\n",
            "8m 29s (- 9m 42s) (35000 46%) 1.2028\n",
            "9m 42s (- 8m 29s) (40000 53%) 1.1035\n",
            "10m 54s (- 7m 16s) (45000 60%) 0.9975\n",
            "12m 7s (- 6m 3s) (50000 66%) 0.8952\n",
            "13m 22s (- 4m 51s) (55000 73%) 0.8138\n",
            "14m 38s (- 3m 39s) (60000 80%) 0.7424\n",
            "15m 51s (- 2m 26s) (65000 86%) 0.6672\n",
            "17m 5s (- 1m 13s) (70000 93%) 0.6099\n",
            "18m 19s (- 0m 0s) (75000 100%) 0.5747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "metadata": {
        "id": "5T7ECR2l7bLS"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "DrLMjHIhGQkk"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukFUutH6GSyW",
        "outputId": "ac297601-037d-4350-93fc-25fa2f9d3754"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> vous etes fort elegante .\n",
            "= you re very sophisticated .\n",
            "< you re very sophisticated . <EOS>\n",
            "\n",
            "> je suis professeur .\n",
            "= i am a professor .\n",
            "< i am a professor . <EOS>\n",
            "\n",
            "> je vais acheter une nouvelle voiture .\n",
            "= i am going to buy a new car .\n",
            "< i am going to buy a new car . <EOS>\n",
            "\n",
            "> je suis juste un simple instituteur .\n",
            "= i am just a humble teacher .\n",
            "< i m just a teacher . <EOS>\n",
            "\n",
            "> je desespere de vous voir !\n",
            "= i m dying to see you .\n",
            "< i m dying to see you . <EOS>\n",
            "\n",
            "> je suis endurant .\n",
            "= i m resilient .\n",
            "< i m resilient . <EOS>\n",
            "\n",
            "> elles sont jetables .\n",
            "= they re disposable .\n",
            "< they re disposable . <EOS>\n",
            "\n",
            "> je n ai pas faim du tout .\n",
            "= i m not at all hungry .\n",
            "< i m not at all hungry . <EOS>\n",
            "\n",
            "> je me rejouis que vous puissiez venir .\n",
            "= i m glad that you can come .\n",
            "< i m glad that you come . <EOS>\n",
            "\n",
            "> elle est bien connue en tant que chanteuse .\n",
            "= she s well known as a singer .\n",
            "< she s well known as a singer . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
        "plt.matshow(attentions.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iohEFWPuGVqk",
        "outputId": "c4f832c6-a546-42a6-c753-43df3bc625d6"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f45dcf12910>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
        "\n",
        "evaluateAndShowAttention(\"elle est trop petit .\")\n",
        "\n",
        "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
        "\n",
        "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPX_L-YEGYss",
        "outputId": "29775d40-83c3-4d88-bdec-ab8108dd2319"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = elle a cinq ans de moins que moi .\n",
            "output = she s five years years than me . <EOS>\n",
            "input = elle est trop petit .\n",
            "output = she s too short . <EOS>\n",
            "input = je ne crains pas de mourir .\n",
            "output = i m not afraid to die . <EOS>\n",
            "input = c est un jeune directeur plein de talent .\n",
            "output = he s a very imaginative . . <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JH6Vw7MfGbNr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}